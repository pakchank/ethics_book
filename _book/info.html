<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="ko-KR" xml:lang="ko-KR"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>2&nbsp; 인공지능과 정보철학/윤리 – 인공지능 시대의 윤리 또는 윤리적 인공지능 - 기술, 정책, 철학</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./post.html" rel="next">
<link href="./basic.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "일치 없음",
    "search-matching-documents-text": "일치된 문서",
    "search-copy-link-title": "검색 링크 복사",
    "search-hide-matches-text": "추가 검색 결과 숨기기",
    "search-more-match-text": "추가 검색결과",
    "search-more-matches-text": "추가 검색결과",
    "search-clear-button-title": "제거",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "취소",
    "search-submit-button-title": "검색",
    "search-label": "검색"
  }
}</script>


<link rel="stylesheet" href="quarto-fonts.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="사이드바 전환" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./first.html">1부: 인공지능 윤리의 철학적 기초</a></li><li class="breadcrumb-item"><a href="./info.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">인공지능과 정보철학/윤리</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="사이드바 전환" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="검색" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">인공지능 시대의 윤리 또는 윤리적 인공지능 - 기술, 정책, 철학</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="검색"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">서문</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./first.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1부: 인공지능 윤리의 철학적 기초</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./basic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">인공지능 윤리의 모색을 위한 철학적, 기술학적 기초</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./info.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">인공지능과 정보철학/윤리</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./post.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">포스트휴머니즘과 윤리적 인공지능</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./second.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2부: 인공지능 윤리의 적용</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">신뢰할 수 있는/책임있는 인공지능 윤리를 위한 가이드라인</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ineq.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">인공지능과 사회불평등</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./labor.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">인공지능과 노동</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./copy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">인공지능과 저작권 -무엇을 보호해야 하는가</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./psych.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">사회적 인공지능의 도덕성 평가: 가상인간의 마음인식을 중심으로</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./third.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3부: 인공지능 윤리의 기술적 접근</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./fml.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">공정한 인공지능을 위한 기술적 해법</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./xai.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">설명 가능한 알고리즘</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">목차</h2>
   
  <ul>
  <li><a href="#서론" id="toc-서론" class="nav-link active" data-scroll-target="#서론"><span class="header-section-number">2.1</span> 서론</a></li>
  <li><a href="#정보적-세계관을-이해하기-왜-사회가-아니라-인포스피어인가" id="toc-정보적-세계관을-이해하기-왜-사회가-아니라-인포스피어인가" class="nav-link" data-scroll-target="#정보적-세계관을-이해하기-왜-사회가-아니라-인포스피어인가"><span class="header-section-number">2.2</span> 정보적 세계관을 이해하기: 왜 ’사회’가 아니라 ’인포스피어’인가?</a></li>
  <li><a href="#정보윤리학과-윤리학의-존재론적-확장" id="toc-정보윤리학과-윤리학의-존재론적-확장" class="nav-link" data-scroll-target="#정보윤리학과-윤리학의-존재론적-확장"><span class="header-section-number">2.3</span> 정보윤리학과 윤리학의 존재론적 확장</a>
  <ul class="collapse">
  <li><a href="#왜-윤리학은-존재론적으로-확장되어야-하는가-피동자-중심존재-중심의-윤리학" id="toc-왜-윤리학은-존재론적으로-확장되어야-하는가-피동자-중심존재-중심의-윤리학" class="nav-link" data-scroll-target="#왜-윤리학은-존재론적으로-확장되어야-하는가-피동자-중심존재-중심의-윤리학"><span class="header-section-number">2.3.1</span> 왜 윤리학은 존재론적으로 확장되어야 하는가: 피동자 중심/존재 중심의 윤리학</a></li>
  <li><a href="#인간-비인간-행위자-네트워크와-분산된-도덕성-이론" id="toc-인간-비인간-행위자-네트워크와-분산된-도덕성-이론" class="nav-link" data-scroll-target="#인간-비인간-행위자-네트워크와-분산된-도덕성-이론"><span class="header-section-number">2.3.2</span> 인간-비인간 행위자 네트워크와 분산된 도덕성 이론</a></li>
  </ul></li>
  <li><a href="#정보권과-윤리적-인간상-인간-중심주의를-재구성하기" id="toc-정보권과-윤리적-인간상-인간-중심주의를-재구성하기" class="nav-link" data-scroll-target="#정보권과-윤리적-인간상-인간-중심주의를-재구성하기"><span class="header-section-number">2.4</span> 정보권과 윤리적 인간상: 인간 중심주의를 재구성하기</a></li>
  <li><a href="#결론" id="toc-결론" class="nav-link" data-scroll-target="#결론"><span class="header-section-number">2.5</span> 결론</a></li>
  <li><a href="#더-생각해볼-문제" id="toc-더-생각해볼-문제" class="nav-link" data-scroll-target="#더-생각해볼-문제"><span class="header-section-number">2.6</span> 더 생각해볼 문제</a></li>
  <li><a href="#더-읽을거리" id="toc-더-읽을거리" class="nav-link" data-scroll-target="#더-읽을거리"><span class="header-section-number">2.7</span> 더 읽을거리</a></li>
  <li><a href="#참고문헌" id="toc-참고문헌" class="nav-link" data-scroll-target="#참고문헌"><span class="header-section-number">2.8</span> 참고문헌</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./first.html">1부: 인공지능 윤리의 철학적 기초</a></li><li class="breadcrumb-item"><a href="./info.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">인공지능과 정보철학/윤리</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">인공지능과 정보철학/윤리</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p><em>유용민 (전남대학교 미디어커뮤니케이션학과)</em><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<section id="서론" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="서론"><span class="header-section-number">2.1</span> 서론</h2>
<p>맥루한(M. Mcluhan)적 의미에서 인간 능력의 확장이라 할 미디어는 이제 인간 존재의 정수에 해당되는 지능적 기능까지 모사함으로써, 미디어를 활용하는 인간 주체의 지위 자체에 질문을 던지고 있다. 미디어 테크놀로지가 인간과의 관계에서 맺는 의미의 본질적, 전면적 변화의 가능성으로 우리 눈앞에 연출되고 있다. 인공지능의 등장으로 현대 정보사회의 성격 또한 새로운 변화의 기로에 서있다. 다니엘 벨(Daniel Bell)이 말했던 정보사회(information society)에서 미디어 테크놀로지는 기껏해야 인간을 보조하는 도구에 불과했지만 지금 등장하고 있는 인공지능 기술은 도구 이상의 의미와 효과로 인간과 관계를 맺어갈 가능성이 점쳐지고 있기 때문이다. 이로 인해 인류 앞에 펼쳐지고 있는 인공 지능 시대를 어떻게 바라볼 것인가와 관련하여 새롭게 등장하는 기술 그 자체와 기술의 활용 방식 및 부작용과 문제점 등을 정확히 알아야 할 필요와 더불어 그러한 것들을 이해하는 데 기존의 지식이 여전히 유효할 것인지도 다시 살펴볼 시점이 도래했다.</p>
<p>전통 지식의 유효성을 다시금 재론해야 할 필요가 커지고 있는 영역 중 하나는 인공지능 윤리 영역이다. 인공지능이 대량의 수행 능력을 발휘하여 인간 삶에 개입하는 자동화 역량과 스스로 계산하여 판단하는 자율성 역량을 기반으로 개인의 삶과 사회 전반에 개입하면서 다양한 도덕적 윤리적 문제들이 발생하고 있고 이런 양상은 더욱 심해질 것으로 전망된다. 전세계적으로 인공지능 윤리 문제에 대한 학술적 논의와 제도적 해법 모색의 열기는 매우 광범위하게 전개되며 뜨겁게 펼쳐지고 있다. 흥미롭게도 정치권력과 기술자본이 늘 윤리를 과학기술의 진보를 발목잡고 혁신을 방해하는 장애물쯤으로 여긴 오랜 역사와 달리 인공지능 윤리 논쟁에 적극 참여하고 있다. 이 양상은 인공지능 기술이 인간과 기술, 기술산업과 윤리의 관계 상의 질적 변화를 초래하고 있음을 시사하는 징후로 해석된다(손화철, 2018; 허유선, 이연희, 심지원, 2020). 물론 이런 변화에 대한 주목은 부분적으로 인공지능 기술에 대한 과도한 환상에 기인하는 면이 없지 않고(이호영 외, 2020; 이희은, 2021), 그에 따라 인공지능 윤리 논쟁이 시기상조의 일들로 호들갑을 떠는 측면도 있다는 주장들(Leslie-Kaelbling, 2021, 10월)도 존재한다. 또는 인공지능의 윤리적 문제성을 기술적 문제로 몰고가는 것은 허상이며 실제로 인공지능은 인간의 힘과 역량을 배가시키는 쪽으로 작용한다는 더 큰 진실을 보았을 때 인공지능에 대한 과도한 의미 부여는 착각에 불과하다는 문제의식들도 있다(김진석, 2019, p.11).</p>
<p>이런 다양한 입장과 관점들을 놓고 인공지능과 윤리의 관계를 이해하기 위해서는 일단 인공지능 기술이 가진 성격과 의미를 어떻게 규정할 것인지부터 중요한 쟁점이 된다. 인공지능을 인간을 대리하여 윤리적 의사결정을 수행하는 주체로 보아야 할지? 실제로 인공지능이 인간과 같이 자아나 의식을 가지고 윤리적 고민이나 선택을 하는 것인지? 이런 쟁점들과 관련하여 인공지능의 성격을 명확히 규정할 수 없다면, 인공지능과 윤리의 관계를 설명하는 것은 쉽지 않을 수 있다. 이 측면에서 인공지능이 실제로 인간과 동일한, 즉 윤리적 주체로 존재할 수 있는지와 관련한 동일 속성이나 형질을 갖는지는 대단히 중요한 문제가 된다. 이러한 문제의식을 도덕적 속성의 실재론적 접근이라고 부른다(Coeckelbergh, 2014). 이러한 실재론적 관점은 인공지능 기술이 실제로 윤리적 행위자가 될 수 있는지 그 실재적 측면에 관심을 거쳐 인공지능 같은 지능형 미디어와 윤리의 관계를 이해하는 접근법으로 나름의 타당성을 갖는다. 인공지능이 스스로 윤리적 사고를 할 수 없는 단순한 도구에 불과하다면 인공지능에 대한 윤리나 정보사회의 윤리 같은 문제는 기존의 지식 틀로 얼마든지 대처가 가능하기 때문이다.</p>
<p>문제는 인공지능과 인간이 맺어가는 관계가 양적 질적으로 나날이 심화되는 상황에 주목할 때 그런 속성이 있는지 없는지 여부와 관계없이 인공지능과 윤리의 관계는 기존의 방식으로 풀어가는 데 한계가 점점 더 커질 것이란 우려에 있다. 예컨대 로봇 비서나 군사용 로봇이 실제로 생각하는 능력이 없다고 해서 단순한 도구로 취급한다면, 인공지능을 학대하거나 비윤리적 목적으로 활용하는 일도 얼마든지 정당화될 수 있다. 이로 인해서 인공지능의 속성에 주목하기보다는 인공지능과 인간이 맺어가는 관계의 확산에 따라 인공지능이라는 새로운 미디어 테크놀로지와 윤리의 관계를 이해하는 지평 자체가 달라지고 있다는 점에 주목해야 할 필요가 있다. 기술과 인간의 관계적 측면에 주목할 때 정보사회의 윤리를 정보를 사용하는 인간을 중심에 놓고 모색했던 기존의 윤리학적 사유의 틀을 넘어선 윤리학적 지평을 재구성할 수 있다.</p>
<p>인공지능 윤리와 관련한 새로운 사유의 틀이 필요한 이유는 또 있다. 앞으로 어떻게 될지는 아직 섣불리 예측할 수 없지만, 미디어 테크놀로지와 인간 사이에 설정된 경계가 나날이 약화되고, 그 구분이 애매모호해지고 있다는 점이다(Mazlish, 1995). 물론 아직 먼 이야기는 하지만, 인류 역사 전체를 놓고 볼 때 인간과 기계, 자연과 인공 사이의 근본적 구분은 끊임없는 불확실성을 향해 달려 왔으며, 유전공학과 정보기술의 발달은 인간과 인간 이외의 존재들 사이에 놓여 있다고 믿겨진 근본적 불연속과 단절 그리고 그러한 불연속과 단절에 근거한 인간 주체의 고유성에 대한 믿음의 약화를 초래했다. 미디어와 인간 신체의 물리적 직접적 연결을 가능케 하는 기술이 점점 더 발전하면서 인간과 비인간 사이에 설정된 전통적인 경계나 위계가 지속될 것이란 믿음도 도전받고 있다. 이처럼 도덕이나 윤리적 쟁점이 형성되는 현실 자체가 기존의 이원론적(dichotomic) 틀에 맞지 않게 변모하고 있다면, 탈이원론적인 방향에서 윤리학적 패러다임의 전환이 고민할 필요가 있다. 현대 윤리학은 그동안 윤리학적 주체를 오직 인간으로만 상정하는 오랜 습속에서 벗어나, 동물, 자연(환경), 지구(가이아) 같은 비인간 범주를 적극적으로 포용하는 방향으로 논의의 지평을 재형성해 왔다. 오직 인간을 중심에 놓고 윤리를 사고하는 전망이 다차원적이고 복합적인 한계에 다다랐다는 문제의식 때문이었다. 이제는 그런 문제의식을 인공지능이라는 포스트 휴먼 시대의 기반 기술에 접목할 때가 도래했다.</p>
<p>이 글에서는 이런 문제의식을 인공지능 시대의 정보철학으로 정립한 이탈리아 출신 정보철학자 루치아노 플로리디(Luciano Floridi)의 정보 철학을 소개하면서, 그의 정보철학에 기초해 인공지능 시대 윤리를 어떻게 이해해 가야 할지에 대해 설명한다.</p>
</section>
<section id="정보적-세계관을-이해하기-왜-사회가-아니라-인포스피어인가" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="정보적-세계관을-이해하기-왜-사회가-아니라-인포스피어인가"><span class="header-section-number">2.2</span> 정보적 세계관을 이해하기: 왜 ’사회’가 아니라 ’인포스피어’인가?</h2>
<p>최근 기술 사회 담론은 현대사회를 4차산업혁명시대, 인공지능사회, 지능정보사회 등 다양한 표현으로 부르고 있지만 그 초점은 정보혁명이라 할 수 있다. 플로리디가 말하는 정보 혁명은 탈-, 후기-사업사회론에서부터 본격적으로 등장한 기존의 미디어-사회 담론과는 다른 의미를 갖고 있다. 기존의 정보혁명은 주로 새롭게 등장한 정보통신기술을 중심에 놓고 사회가 작동하는 방식을 설명하고자 했다면, 플로리디가 말하는 정보사회는 우리, 즉 인간이 누구인가에 관한 이해의 문제를 끌어들인다는 점에서 기존의 정보사회 이론들과는 구별된다. 첫째, 플로리디에 따르면, 기존의 정보혁명론들은 대부분 인터넷혁명, 디지털혁명이 정보에 관한 최초의 혁명인 것처럼 설명한다. 그러나 플로리디가 볼 때, 인간은 초기 문자를 발명했을 때부터 정보적 삶을 살아 왔기 때문에, 문자 정보를 도구로 삼기 시작한 기술적 조건의 출현 때부터 사회의 정보적인 차원은 존재했다는 것이다. 둘째, 플로리디의 관점에서 정보는 도구, 자원의 범주가 아니라 우리가 살아가는 환경, 인간의 행위를 가능케 하면서 동시에 제약하는 조건 그 자체라는 점이다. 셋째, 인류 역사는 정보를 전달, 저장하는 시대를 넘어서 정보 환경 그 자체를 존립 조건으로 삼는 단계로 넘어왔다는 역사의식이다.</p>
<p>정보를 이해하는 플로리디의 논의에서 주목할 부분은 정보라는 것이 인류 역사에서 기존에는 존재하지 않았는데 기술 발전에 의해 출현한 것이라고 이해하기보다는 인류 역사 전체에 항상 존재했던 것으로 간주해야 한다는 관점에 있다. 이러한 관점에서 플로리디는 바이오 스피어(biosphere)와 인포 스피어(infosphere)를 구분한다. 플로리디에 따르면 인포스피어는 물질, 지구, 자연 환경 같은 바이오스피어에 그 존재 자체가 가려져 있었지만, 기술 발전에 의해 인식될 수 있었다고 본다. 인포스피어라는 개념은 왜 중요할까? 그것은 기존의 정보윤리나 정보철학이 정보를 사유하는 거리는 (인간이) 정보를 어떻게 다루어야 하는가?에 국한되었다면, 인포스피어 개념은 정보 자체를 중심에 놓고 세계를 인식하는 관점을 열어주기 때문이다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="pics\info-1.png" class="img-fluid figure-img"></p>
<figcaption>&lt;그림 1&gt; 정보권(inforsphere)</figcaption>
</figure>
</div>
<p>출처: http://si410wiki.sites.uofmhosting.net/index.php/Infosphere</p>
<p>이를테면 플로리디는 인포스피어는 인간이 자연, 물리적 조건에서 살아가는 시공간이 아니라 모든 정보적인 행위자들이 서로 상호작용하는 환경이라고 말한다(Floridi, 2014, pp.25-48). 얼핏 보면 인포스피어 개념은 온라인 공간이나, 사이버 세계, 디지털 공론장 같은 개념과 별 다를 바 없어 보인다. 그러나 플로리디의 인포스피어 개념은 온/오프라인을 모두 포괄하는 개념으로, 정보를 주고 받으며 상호작용하는 모든 존재들이 공존하는 장이다. 이런 공간적 발상이 특히 의미있는 부분은 인간과 비인간 존재들 사이의 관계성, 연결성에 특히 주목할 수 있게 하기 때문이다. 따라서 플로리디는 인간, 로봇, 인공지능, 사물인터넷 같은 기술적 존재들이 모두 관계를 맺는 부분을 이야기하기 위해서 기존의 ’사회’라는 개념 대신 정보적 장, 즉 정보권이라고 표현한다.</p>
<p>플로리디가 사회라는 개념보다 인포스피어라는 표현으로 세계를 규정하는 또 다른 이유는 윤리적 문제가 이제는 인간과 도구, 인간과 인간 사이에서만 형성되지 않기 때문이다. 이는 플로리디의 3차 기술 개념(Floridi, 2014, pp.25-32)<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> 을 보면 잘 나타난다. 인간과 직접 상호작용하지 않고 컴퓨터나 거대 데이터 센터 내부에서 기술과 기술 사이에서만 서로 교류하는 커뮤니케이션 과정들을 생각해 보자. 이 기술들은 인간과 일상적으로 결코 접촉하지 않는다. 뿐만 아니라 이런 기술들은 인간의 직접적 통제와 조작 관리가 없어도 독립적 혹은 준-독립적으로 행위한다. 더구나 이 기술들은 데이터 학습을 통해서 시스템 내부에서 인간의 의도적 개입이나 통제가 없더라도 자신의 내적 상태가 변화될 수 있는 성격을 가진 존재이다. 문제는 내적 상태가 변화하면, 행위가 변할 수 있고, 그러면 그 행위의 윤리성도 변할 수 있다는 점이다. 즉, 여기서 인공지능은 윤리적 자아나 의식의 보유 여부와 무관하게 윤리적 존재성을 갖는다. 일반인공지능 출현 가능성의 관건 요소로 주목받는 마음(mind)이나 심리적 지향(orientation)이 없다 하더라도 자율적 존재로서의 의미를 부여할 수 있다는 것이다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="pics\info-2.png" class="img-fluid figure-img"></p>
<figcaption>&lt;그림 2&gt; 1차 기술, 2차 기술, 3차 기술</figcaption>
</figure>
</div>
<p>출처: http://si410wiki.sites.uofmhosting.net/index.php/Infosphere</p>
<p>물론 3차 기술들도 인간의 설계와 학습, 그리고 통제 범위 안에서 행위하기 때문에, 3차 기술의 의미를 지나치게 과장할 수 없다는 반론도 가능하다. 하지만, 인공지능과 로봇의 자율성과 인간의 자율성이 똑같은 발생학적(embryological) 조건을 공유한다는 가정이 없어도, 인공지능이나 로봇의 자율성은 실존한다.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> 따라서 이러한 기술들이 서로 어떻게 상호작용하는지에 따라 다양한 윤리적, 도덕적 문제들이 형성되는 현실에서 윤리학의 영토는 더 이상 인간의 도덕적 행위에 국한된 문제의 지평으로 설정되기가 어렵다. 이런 지점들을 윤리학적으로 ’포착’하기 위해서는 세계 자체를 정보적으로 재규정할 필요가 있음을 시사한다. 이러한 측면에서 플로리디는 정보 윤리를 말하기 이전에 세계를 정보적으로 이해해야 한다고 주장하는 것이며, 정보적 관점에서 세계를 이해하려는 노력이 바로 플로리디가 말하는 정보철학인 셈이다.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
</section>
<section id="정보윤리학과-윤리학의-존재론적-확장" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="정보윤리학과-윤리학의-존재론적-확장"><span class="header-section-number">2.3</span> 정보윤리학과 윤리학의 존재론적 확장</h2>
<section id="왜-윤리학은-존재론적으로-확장되어야-하는가-피동자-중심존재-중심의-윤리학" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="왜-윤리학은-존재론적으로-확장되어야-하는가-피동자-중심존재-중심의-윤리학"><span class="header-section-number">2.3.1</span> 왜 윤리학은 존재론적으로 확장되어야 하는가: 피동자 중심/존재 중심의 윤리학</h3>
<p>플로리디의 정보윤리학은 인간은 물론 인간 이외의 존재들을 정보라는 근본 범주의 관점에서 바라보는 존재론적 시각을 바탕으로 존재들 일반에 적용 가능한 일반 윤리 이론을 지향한다. 쉽게 말하면 윤리학을 인간 윤리학에서 끄집어 내 정보적 존재 모두의 윤리학으로 재편하자는 것이다. 자유주의든, 공화주의든, 공동체주의든, 공리주의든, 의무론이든 현대 윤리학의 모든 이론의 중심에는 인간이 놓여 있다. 현대사회가 도덕적 책임을 개별 인간이나 인간 집단 차원에서 논의하는 방식(Miller, 2001)은 따라서 동물, 자동차, 바위, 컴퓨터, 인공지능에게 윤리적인 책임을 물을 수 없다. 그들은 윤리적 행위자의 범주에 속하지 않기 때문이다.</p>
<p>예컨대 로봇이 인격을 갖는지 여부를 기준으로 접근하면 로봇에 대한 학대나 비윤리적 활용은 아무런 문제가 되지 않는다. 로봇은 보통 인간을 돕기 위해 만들어지고 배치된다. 따라서 로봇과 인간 사이에는 서로를 윤리적으로 배려하고 대우해야 할 관계에 대한 도덕적 고려가 적용되어야 한다. 인간은 로봇을 돌보고, 로봇은 인간을 돌본다. 하지만 현 단계 로봇은 독립적 인격체가 아니기 때문에 인간이 로봇에 책임을 물어야 할 이유는 기각된다. 더구나 그런 책임성은 엄격한 인과성(causality)의 해명에 기반해야 하는데, 실제로는 그런 책임을 어떻게 물을지 모호하다. 로봇의 머리 속에 자리잡은 블랙박스 같은 인공지능이 행한 결과가 설계자가 유도한 결과인지 설계자의 의도와는 전혀 무관하게 발생한 것인지를 투명하게 밝히기 어렵다.</p>
<p>이런 난해한 문제는 비단 인공지능과 인간 개인의 관계에서만 발생하지 않는다. 인공지능이 대량의 정보를 처리하면서 사회가 돌아가는 오늘날 거시적인 측면에서 발생하는 도덕적 해악과 고통을 누구의 책임으로 물어야 할지는 점점 더 복잡하고 불투명한 문제가 되고 있다. 그 이유 중 하나는 인간과 다양한 기술적 요인들이 복잡하게 얽혀 있기 때문이다. 오늘날 현대 사회에서의 도덕적 이슈들은 단순히 특정 행위자를 단일 원인으로 하기보다, 복잡한 행위자들의 하이브리드적 연결망(network) 차원에서 발생하고 있음에 주목해야 한다. 윤리학적 이슈와 쟁점들이 연결망의 차원에서 발생하는 현실에서 인간 행위자의 윤리적 의도와 동기에 근거한 윤리학적 사고는 실제 현실에서 윤리적 반성이나 성찰을 이끌어내기 어렵다는 한계점도 고려해야 한다. 포스트 휴머니즘 시대에 인간의 가치를 비판적으로 재해석하는 이론가들이 강조하는 것처럼, 인간 중심의 윤리학이란 애초부터 서구 자유주의에 대한 옹호 속에서 태어난 것에 불과하며(Braidotti, 2019), 디스토피아 담론들이 말하는 인간성이라는 가치는 보편적인 가치로 존재한 적이 없다(Ferry, 2015). 인간 중심의 윤리는 권력을 다른 말로 표현한 것의 일부이며, 따라서 비서구, 여성, 유색 인종은 물론이거니와 동물 윤리, 생태 윤리 같은 다른 차원의 윤리적 요청들로부터 끊임없이 도전받은 역사를 갖고 있다.</p>
<p>인공지능에 관한 많은 논의들이 인공지능이 인간의 가치를 위협할 것이란 가정에 의존하고 있지만, 실제 현실을 보면 인공지능은 인공지능을 정치적, 경제적으로 이용하거나 이를 악용하려는 인간적, 집단적 의지의 도구로 전락하는 경우들이 보다 진실에 가깝다. 인공지능, 빅데이터, 로봇이 새로운 위험사회의 기술적 요인이라는 비판들과 달리 그 기술들이 윤리적으로 대우를 받지 못하는 문제를 거꾸로 살피는 것이 정보사회의 윤리가 된다고 말할 수 있다. 인공지능이나 로봇이 학대를 당하는 경우도 인간의 눈으로만 보아서는 기술과 인간의 윤리적 공존에 적절한 결과를 이끌어내기 어렵다. 플로리디가 윤리적 세계에서 행위자 범주를 기존의 인간 중심 또는 넓게 봐서 생명 중심에서 존재 중심적 관점으로 대체하고, 기술적 인공물들까지 포용하려는 배경이 여기에 있다.</p>
<p>플로리디의 정보윤리학은 윤리적 책임을 규명하는 방식에 대해서도 새로운 구상을 고민한다. 기존의 윤리학은 도덕적 이슈와 쟁점을 행위자의 책임을 엄격하게 해명하는 방식에 의존한다. 이 말은 반대로 말하면 행위되지 않은 일에는 윤리적 책임을 논하기가 불가능하진 않더라도 매우 까다롭다는 의미(Scheffler, 2001; Singer, 1975)를 내포한다. 책임이 있는 행위자와 그렇지 않은 행위자를 명확히 구별하기 어려운 상황에서도 마찬가지다. 가령 사물인터넷 등 지능화된 디지털 테크놀로지들이 정교하고 복잡하게 결합된 스마트 시티에서 벌어지는 문제들은 그 책임 주체가 정확히 누구일까? 즉 책임의 원인이 누구에게 얼마만큼 할당되는지가 불분명한 상황에서는 타인과 사회에 도덕적 해악이나 고통을 발생시킨 원인 제공자를 특정하고 문제가 된 행위와 원인 제공자 사이의 명확한 인과성을 규명하기 어렵다. 인간과 기계, 기계와 기계 사이의 경계가 모호해지고 신경과학과 나노 테크놀로지 등 과학기술의 발달과 유기체와 기계 장치들 사이의 결합이 점점이 점점 더 이음새나 마찰 없이 연결됨에 따라서 이런 문제는 더 보편성을 띌 것으로 전망된다.</p>
<p>플로리디는 책임이 형성되는 방식이 달라진 상황에서 각각의 행위자들의 성격은 도덕적으로 중립적인 행위자가 되어간다는 점 또한 문제시 삼는다(Floridi, 2013b). 인터넷 상에서 미디어 이용자들은 미시적 수준에서 도덕적 이유에 대한 책임을 져야 할 이유가 없는 행동들을 하지만, 이 행동들이 누적되고 중첩, 연결되면서 강한 도덕적 파급력을 지닌 결과들이 산출되는 일은 정보사회에서 흔한 일이 되었다. 그렇다면 과연 이들에게 어떻게 책임을 물어야 할까?</p>
<p>이런 딜레마를 돌파하기 위해 플로리디는 행위자 중심의 윤리학을 폐기하고 대신 피동자 중심 (patient oriented)의 윤리학 또는 존재 중심적 윤리학(onto-centric ethics)을 도입함으로써 정보권(inforsphere) 시대의 도덕적 책임에 관한 윤리학을 재구성하려고 한다. 피동자 중심의 윤리학이란 정보권을 구성하는 일원으로서 정보적 시스템으로 이해가 가능한 모든 존재들에 해당되는 윤리학이다. 피동자 개념이 윤리학적 주체에 적용되어야 할 근거는 행위하지 않더라도 도덕적 책임을 적용할 수 있어야 하기 때문이다. 따라서 정보권을 구성하는 모든 존재들은 도덕적 의지와 마음을 갖춘 인간 뿐만 아니라 그 이외에 존재들, 특히 인공지능, 로봇, 사물 인터넷과 그밖의 미디어들을 모두 포함한다. 도덕적 존재들의 범위를 확장한다는 것은 도덕적으로 사고하고 행동할 줄 아는 인간이 아니더라도 도덕적 고려의 대상이 되어야 할 필요가 있기 때문에 이들의 자격 요건을 최소한도로 낮춘다는 것이다.</p>
<p>피동자들에 대한 정보윤리학적 주목은 기존의 생명 중심의 윤리에서 정보 중심의 윤리로의 전환을 의미한다. 디지털 생태계에서 작동하는 기술적 인공물들은 생명이 없다 하더라도 윤리적으로 대우를 받아야 할 존재들이며, 여기서 인간 윤리냐 로봇 윤리라는 구분은 조금 덜 중요하다. 예를 들어 국내에서 인공지능 윤리 논쟁을 불러일으켰던 이루다 논란의 경우를 보면, 이루다가 도덕적으로 사고하거나 행동할 수 있는 존재이냐 아니냐가 중요한 것이 아니라 성희롱, 성착취 같은 비윤리적 행위에 대한 문제의식이 핵심이다. 이처럼 우리 모두가 피동자라는 동등한 자격을 부여받게 되면 서로가 서로를 윤리적으로 대해야 할 의무가 도출될 수 있다. 생명 중심의 윤리는 생명이 있는 것은 윤리적으로 우대하지만, 생명이 없는 무기 물질이나 기계는 함부로 대할 수도 있는 가치를 은연 중에 함축한다. 따라서 도덕적 사고와 윤리적 고려를 비생명적 존재들까지 확대해서 적용한다는 것은 행위자들로 하여금 자신의 도덕적 판단과 그에 입각한 행위 수행 시 그로부터 영향을 받는 모든 존재들을 적극적으로 고려해야 한다는 윤리적 요청의 당위적 토대를 제공한다.</p>
</section>
<section id="인간-비인간-행위자-네트워크와-분산된-도덕성-이론" class="level3" data-number="2.3.2">
<h3 data-number="2.3.2" class="anchored" data-anchor-id="인간-비인간-행위자-네트워크와-분산된-도덕성-이론"><span class="header-section-number">2.3.2</span> 인간-비인간 행위자 네트워크와 분산된 도덕성 이론</h3>
<p>다음으로 분산된 도덕성에 관한 플로리디의 윤리학적 구상은 정보권의 특성에 따라 요청되는 윤리학적 모델이다. 플로리디는 정보권 하에서 도덕적 해악은 행위자들 사이의 복잡한 상호작용 과정에 의해 윤리적 문제로 쟁점화 되고 있다는 점에 주목한다(Floridi, 2013a, 2014). 이 점이 도덕과 윤리에 미치는 영향은 어떤 윤리적 이슈가 개별 행위자에 의해 일어난다기보다는 행위자들의 연합 즉 네트워크에 의해서 발생한다는 점에 있다. 이러한 상황은 도덕적 문제에 대한 책임의 특정한 원인 제공자를 확정하기가 어려우며, 그에 따라 인간, 비인간 존재들이 상호작용하는 과정들 속에서 각각의 행위자들 혹은 행위자처럼 기능한 기계들은 대부분 도덕적으로 중립적인 지위를 가지는 것처럼 보이는 결과를 야기하며, 기술과 인간의 상호작용이 점점 더 복잡한 양상을 그려감에 따라 도덕적 윤리적 문제에 대한 대처는 까다로워진다.</p>
<p>플로리디는 이러한 난관을 돌파하기 위하여 분산된 도덕성(distributed morality)과 분산된 도덕적 행위(distributed moral action) 개념을 도입한다(Floridi, 2013a, p.&nbsp;137, pp.&nbsp;261-276). 분산된 도덕성 개념을 통해 플로리디는 대부분의 행위자들이 도덕적으로 중립적인 것처럼 보이지만 실제로는 도덕적 해악에 관여되는 상황의 윤리적 책임을 규명할 수 있는 대안을 제시한다. 분산된 도덕성의 상황에서 원인 제공자를 특정하기가 어려운 상황은 반대로 말하면 전체 행위자들의 작은 참여와 노력을 통해서 도덕적 상황을 개선할 수 있는 역설적 가능성을 갖는다. 가령 영향력 측면에서 무시해도 좋을 개별 행위자들의 상호작용이 가능하다면, 디지털 네트워크 상에서 발생하는 도덕적·윤리적 이슈들에 대한 대처는 효율적으로 가능하다(Floridi, 2013b).</p>
<p>분산된 도덕성 모델은 도덕적으로 중립적인 것처럼 보이지만 실상은 도덕적 해악에 연관되는 행위자들 사이의 상호작용에 주목함으로써, 어떤 도덕적 악이 초래될 때 그것에 책임을 할당하는 문제를 어떻게 이론적으로 재구성할 것인지에 주목한다(Floridi, 2013a, 2013b). 이를 위해 플로리디의 분산된 도덕성 모델은 강한 인과성의 규명에 의존하기보다는 관련성(relevance)에 가까운 약한 인과성(week causality)에 주목한다. 내가 의도가 있었는지 여부보다는 어떤 연관성이 있었는지에 따라 인과적 해명 책임이 요구될 수 있다. 이러한 접근의 이점은 도덕적 관련성이 있는 주체들의 참여와 연대를 유도할 수 있다는 장점을 제공한다. 이런 접근에서 중요한 점은 의지나 의도가 없더라도 책임에 관해 고려해야 할 필요가 있다는 것이다. 플로리디가 “마음이 없는 윤리학(mindless ethics)” 혹은 “과실이 없는 책임” 이론의 필요성을 강조하는(Floridi, 2013a, pp.&nbsp;148-152) 이유다. 그가 윤리학적 개념들을 이렇게 마음, 의식, 의도 없는 행위/행위자의 측면에서 재정의하려는 이유는 다시금 자율성의 문제가 관건이 되기 때문이다. 인간 이외의 알고리즘이나 인공지능, 로봇 같은 인공적인 행위자들이 강한 인과성이 없더라도 도덕적 판단에 개입하는 과정에서 발생하는 윤리적 책임을 어떻게 귀속시킬 것인가를 둘러싼 이론적 발판을 모색하는 것이다.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="pics\info-3.png" class="img-fluid figure-img"></p>
<figcaption>&lt;그림 3&gt; 분산된 도덕성 모델 (distributed morality model)</figcaption>
</figure>
</div>
<p>출처: https://link.springer.com/article/10.1007/s11948-012-9413-4</p>
<p>그렇다면 이 지점에서 왜 우리가 피동자들을 윤리적으로 대우해야 하고, 보다 광범위한 존재들 그리고 그 존재들 사이에 도덕적 관계의 윤리학적 당위와 규범을 설정해야 하는가라는 질문이 제기될 수 있다. 왜 기계들에게도 인간 사이에만 성립하는 윤리적 관계라는 문제를 적용해야 하는가? 이에 대해 플로리디는 고통 같은 질적인 의미를 갖는 윤리학적 개념을 엔트로피(entropy)라는 정보적인 개념으로 대체하여 정보 환경에서 왜 윤리가 보편적으로 적용되어야 하는지에 대한 나름의 논리를 제공한다(Floridi, 2013a, pp.&nbsp;65-84). 그것은 고통 같이 윤리학적으로 우리가 피해야 하는 개념을 엔트로피라는 정보적인 표현 형식으로 대체하는 논리로, 생명의 개념에서 보다 확장된 존재 일반에 있어서 고통은 정보적인 무언가로 재개념화하려는 시도다. 모든 정보/존재는 자신의 본질적인 가치, 즉 의미를 지니고 있고 존재 자체가 번성할 권리를 갖는다. 만약 어떤 정보나 정보적 존재, 예를 들어 로봇이 인간의 학대나 오용으로 인하여 자신의 존재가 궁핍해지는 상황에 처한다면 엔트로피는 증가한다. 플로리디는 이를 정보윤리 원칙으로 설명한다(Floridi, 2013a, pp.70-73). 그 원칙은 첫째, 엔트로피는 정보 환경에서 방지되어야 하고, 둘째, 엔트로피는 정보 환경에서 제거되어야 하고, 셋째, 전체 정보 환경은 물론 개별 정보적 존재들의 번영, 즉 그들의 잘 삶(well-being)이 고취되어야 한다는 것이다.</p>
</section>
</section>
<section id="정보권과-윤리적-인간상-인간-중심주의를-재구성하기" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="정보권과-윤리적-인간상-인간-중심주의를-재구성하기"><span class="header-section-number">2.4</span> 정보권과 윤리적 인간상: 인간 중심주의를 재구성하기</h2>
<p>플로리디 정보윤리학은 인간 뿐만 아니라 비인간 존재들까지 윤리학적 고려 대상으로 간주하려는 윤리학의 확장은 윤리적 존재로서의 인간이 갖는 가치나 의미를 축소시키려는 접근으로 평가될 수 있다. 그러한 점에서 인포스피어에서 인간의 존재 이유, 인간의 의미와 가치 그리고 윤리적 역할 상은 어떻게 되는 것인가에 관한 물음이 제기된다. 이에 대해 플로리디는 호모 포이에티쿠스(homo poieticus)라는 은유를 통해서 정보권에서 인간의 윤리적 지위를 재모색한다.</p>
<p>호모 포이에티쿠스 개념은 호모 파베르(homo faber), 호모 에코노미쿠스(homo economicus), 호모 루덴스(homo ludens)라는 인간에 대한 기존 개념들과는 구별되는 윤리적 인간 상을 조명하는 개념이다. 호모 파베르는 자연, 생명 그리고 기계를 비윤리적 목적으로 활용하는 인간의 모습이 반영되어 있다. 호모 에코노미쿠스도 마찬가지로 인간의 경제적 측면, 즉 자본의 증식과 유통 그리고 소비에 매몰된 인간의 한계성을 담고 있다. 호모 루덴스 또한 유희적 인간이 타자를 배려하지 못하거나 자신의 놀이와 유희에 빠진 나머지 그로부터 유발될 수 있는 도덕적 해악에 대한 책임성이 결여되어 있는 인간상을 설명하는 개념이다. 인간에 대한 이러한 기존 정의들은 공통적으로 인간 중심적 인간성에 내재된 윤리적인 한계를 안고 있다. 이에 반해 플로리디는 정보권에서 인간이 가진 윤리적 역할을 강조하기 위한 의도에서 호모 포이에티쿠스 개념을 내세운다(Floridi, 2013a, pp.161-179). 호모 포이에틱스로서의 인간은 에코 포이에틱한 존재인데, 이는 정보권 내에서 모든 존재들을 관리해야 하는 윤리적 책임을 자각하는 인간이자 정보권 환경을 도덕적으로 구성하는 과정에 적극 참여해야 하는 윤리적 의무를 지닌 인간 존재를 뜻한다.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<p>플로리디는 정보권 시대에 인간의 역할이 축소되거나 배제되는 기술소외론 또는 기술 혐오론과는 정반대로 인간의 역할에 더 큰 의무와 책임을 부여하고 있다. 이는 인간 이외에도 기술이 스스로 사고하고 행동하는 주체로 발전할 수 있는 가능성이 점쳐지는 인공지능 시대의 조류와는 맞지 않는 분석인 것처럼 보일 수 있다. 그러나 플로리디가 말하고자 하는 바는 인간과 비인간은 정보권을 함께 만들어가는, 즉 구성해가는 존재라는 점에 주목해서 포스트 휴머니즘 시대에 인간의 윤리적 역할이 더 축소된다는 관점을 거부해야 한다는 것이다. 왜 이렇게 바라볼까? 그것은 인간이 피동자 혹은 존재들에 대한 더 많은 의무와 책임을 지는 상황이 연출되고 있기 때문이다. 예컨대 과거의 테크놀로지가 사회에 미치는 영향력의 도달 범위나 파급력은 제한적이었지만 현대사회의 기술들이 사회에 미치는 영향력의 도달 범위와 파급력은 다르다. 그런 기술을 개발, 보유, 운영하는 인간은 환경에 더 큰 영향력을 행사할 수 있다. 정보권에서 인간에 더 큰 윤리적 의무와 책임이 부여되는 것은 이 때문이다. 인공지능과 관련해서 생각해 보자. 인간은 인공지능이라는 아이를 낳아서 키우는 부모 입장이 된다. 따라서 인공지능이라는 존재를 돌볼 도덕적 의무와 윤리적 역할은 여전히 중요하다. 아이가 자라 스스로 사고하고 행동한다 하더라도, 그 아이의 생각과 행동에 대해 부모가 윤리적 책임을 지는 문화는 아이가 진짜 인간이든 로봇이든 차이를 두어야 할까? 오히려 그 차이를 두지 않을 때 인간이라는 존재의 윤리학적 의미는 더욱 풍성해지고 그 존재 의의가 지속되는 것은 아닐까?</p>
<p>인공지능이 단순한 도구가 아니라 인간과 같은 진정한 행위자로 진화한다 해도 인간이 가진 존재론적 의미는 퇴색되지 않는다는 플로리디의 정보철학은 요즘 유행하는 인공지능에 대한 인문학적 비평들이 가진 한계점을 비판한다. 전통적 휴머니즘이나 고전적 인문학의 관점에서 기술의 비윤리성을 무작정 비판만 하는 것으로는 현실의 윤리적 변화를 이끌어 내기 어렵기 때문이다. 오히려 무작정 인간 중심성을 외치는 방식은 휴머니즘의 미래 가능성을 제약하는 효과만 일으킬 수 있다. 심지어 전통적인 휴머니즘에 입각한 기술 비평들은 현실에서 인간에 의해 야기되는 도덕적 해악들을 제대로 비판하지도 못한다는 점에서 쓸모가 적다고 말할 수도 있다. 기술을 윤리적으로 악용하는 사회 구조나 질서 그리고 정치경제학적 불평등 같은 문제들을 이야기하지 않은 채 ’인간’의 가치만을 이야기하는 것은 추상적으로는 아름답게 들릴지 몰라도 실제 현실을 분석하는 데에는 실천적인 이론이 되지 못한다.</p>
<p>이러한 맥락에서 플로리디의 정보철학은 단순히 인간 중심성을 극복하거나 탈피하자는 최근의 포스트휴머니즘적 사고와 미묘한 차이를 보인다. 즉 그는 인간 중심주의를 폐기하기보다는 오히려 인간 중심주의를 재구성하고, 그 본래 의미를 재발견 해가자는 쪽에 가깝다. 실제로 플로리디의 정보철학에서는 존재론의 확장과 이를 수용하는 윤리학의 체계를 이야기할 뿐, 기술과 인간 사이에 누가 더 우월한지, 기술과 인간 사이의 위계가 어떻게 결말 지어질 것인가에 대한 이론적 시나리오를 상정하지 않는다.</p>
</section>
<section id="결론" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="결론"><span class="header-section-number">2.5</span> 결론</h2>
<p>플로리디의 정보윤리학은 정보적 세계에 걸맞은 보편 윤리학의 토대를 제시한다. 그의 윤리학은 존재론적 토대 위에서 세계 내 존재들 간의 윤리적 관계를 어디까지 전망할 수 있을지에 관해서 또 한번의 새로운 확장을 요청한다. 이렇게 윤리학의 경계를 확장하려는 시도는 물론 현대 윤리학에서 새로운 시도는 아니다. 윤리학은 과학기술윤리, 동물윤리, 환경윤리 등 윤리학의 경계에 대한 끊임없는 확장을 추구해 왔다. 플로리디는 마치 라뚜르(B. Latour)처럼 인간과 비인간의 복잡다양한 연결들에 기초해 구성되는 정보권이 도덕적인 세계로 나아가기 위해서 기존 윤리학의 대전제들부터 넘어서고자 한다. 마음이 없는 윤리학, 피동자 중심/존재 중심의 윤리학, 분산된 도덕성 모델들은 바로 그런 원리들이다.</p>
<p>물론 플로리디의 정보윤리학적 원리들은 추상적인 수준의 설명에 머물러 있기 때문에 이러한 원리들을 현실에 구체적으로 적용할 수 있는 수준에서 윤리학적 처방을 제시해주진 않는다. 그럼에도 불구하고 플로리디의 정보윤리학이 제공하는 시사점은 적지 않다. 무엇보다 윤리적 세계의 범위를 어디까지 얼마만큼 설정할 것인가와 관련해서 그의 정보권적 관점은 온라인과 오프라인의 경계가 해체되고 정보가 영향을 미치는 범위가 급속도로 확산되는 오늘날 상당한 설득력을 보여준다. 디지털 장치와 네트워크에 의존하는 사회적 커뮤니케이션 시스템 안에서 인간이 커뮤니케이션 하는 대상은 이미 인간이 아닌 지능화된 컴퓨터 장치가 되고 있다. 이러한 소통적 조건에서 더 이상 윤리적 타자는 인간 범주로 환원되지 않으며, 윤리적 타자는 이제 인공지능 같은 기술적 인공물들로 확대되어야 한다.</p>
<p>지금의 많은 인공지능 윤리 담론들은 자본과 권력, 민족과 인종, 젠더 등 다양한 차원에서 위계적이고 불균등한 인간 관계들이 지속되고 있는 사회적 조건의 지속 안에서 기술이 차이와 다양성을 넘어서 불평등과 차별을 야기하는 비윤리적 상황을 막기 위해서 인간 중심주의에 호소하고 있다. 그러나 이런 인공지능 윤리 담론들은 인간과 비인간들이 상호작용하는 네트워크로서의 사회를 실질적으로 윤리화 하자는 지향보다는 인공지능이 기술 제공자와 소비자 사이에서 윤리적 충동을 일으키지 않는 범위 내에서 작동하게 만드는 데 큰 관심이 있는 것처럼 보인다. 인공지능 윤리가 이렇게 협소하게 적용되면 인공지능 윤리라는 개념은 인공지능과 더불어 변화하는 세계에서 발생 가능한 비윤리적 측면들을 윤리적으로 세탁하는 도구로 전락될 수도 있다(Vincent, 2019).</p>
<p>인공지능이 진정한 도덕적 행위자가 될 수 있느냐 없느냐 같은 본질주의적 접근 방식으로 인공지능 윤리를 논쟁하는 것은 어쩌면 덜 중요한 쟁점이다. 그렇게 될 가능성이 있든 없든, 정보권이 도덕적인 세계로 나아갈 수 있는지 없는지가 윤리학적 핵심이다. 따라서 트랜스 휴머니즘이나 포스트 휴머니즘의 거친 파도 속에서도 정보적 세계에 대한 윤리적 책임을 회피하지 않으려는 인간적 태도를 가진 인간관이 더욱 절실히 요청되는 역설에 주목할 필요가 있다. 그런 면에서 플로리디의 정보철학은 전통 윤리학과 탈 인간 중심주의 사이를 연결짓는 다리 이론인 것으로 보인다.</p>
</section>
<section id="더-생각해볼-문제" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="더-생각해볼-문제"><span class="header-section-number">2.6</span> 더 생각해볼 문제</h2>
<ol type="1">
<li><p>’사회’라는 개념과 ’정보권’이라는 개념의 차이가 무엇일지 고민해 보자.</p></li>
<li><p>’인간을 위한 인공지능’이나 ’좋은 사회를 위한 인공지능’이란 표현을 윤리학의 관점에서 비판적으로 평가해 보자.</p></li>
<li><p>로봇, 인공지능, 스마트 미디어를 왜 윤리적으로 대해야 할까에 대해 고민해 보자.</p></li>
<li><p>디지털 상에서 발생하는 도덕적 이슈들에 대한 책임을 어떤 방식으로 따져야 할지에 대해 고민해 보자.</p></li>
</ol>
</section>
<section id="더-읽을거리" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="더-읽을거리"><span class="header-section-number">2.7</span> 더 읽을거리</h2>
<p>목광수 (2023). 루치아노 플로리디, 정보 윤리학. 서울: 커뮤니케이션북스.</p>
<p>Luciano Floridi. 석기용 역. (2022). 정보철학 입문. 서울: 필로소픽.</p>
<p>마크 코켈버그. 신상규, 석기용 역. (2023). AI 윤리에 대한 모든 것. 파주: 아카넷.</p>
<p>Durante, M. (2018). Ethics, Law and the Politics of Information: A Guide to the Philosophy of Luciano Floridi. Dortrecht: Springer.</p>
</section>
<section id="참고문헌" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="참고문헌"><span class="header-section-number">2.8</span> 참고문헌</h2>
<p>허유선·이연희·심지원(2020). 왜 윤리인가: 현대 인공지능 윤리 논의의 조망, 그 특징과 한계. &lt;인간·환경·미래&gt;, 통권24권, 165-209.</p>
<p>손화철 (2018). 인공지능 시대의 과학기술 거버넌스. &lt;철학사상&gt;, 68권, 267-299.</p>
<p>Braidotti, R. (2019). Posthuman knowledge. Cambridge, UK: Polity Press.</p>
<p>Coeckelbergh, M. (2014). The moral standing of machines: Towards a relational and non-Cartesian moral hermeneutics. Philosophy &amp; Technology, 27(1), 61-77</p>
<p>Ferry, L. (2015). La révolution transhumaniste. Paris, France: Plon.</p>
<p>Floridi, L. (2008). The method of levels of abstraction. Minds and Machines, 18(3), 303–329.</p>
<p>Floridi, L. (2013a). The Ethics of Information. Oxford: Oxford University Press.</p>
<p>Floridi, L. (2013b). Distributed morality in an information society. Science and Engineering Ethics, 19, 727–743.</p>
<p>Foridi, L. (2014). The Fourth Revolution: How the infosphere is reshaping human reality. Oxford: Oxford University Press.</p>
<p>Floridi, L. (2017). A plea for non-naturalism as constructionism. Minds and Machines, 27, 269–285.</p>
<p>Floridi, L., &amp; Sanders, J. W. (2001). Artificial evil and the foundation of computer ethics. Ethics and Information Technology, 3(1), 55–66.</p>
<p>Floridi, L., &amp; Sanders, J. W. (2004). On the morality of artificial agents. Minds and Machines, 14(3), 349–379.</p>
<p>Formosa, P. (2021). Robot autonomy vs.&nbsp;human autunomy: Socia robots, Aritificial Intelligence(AI), and the nature of autonomy. Minds and Machines, 31(4), 595-616</p>
<p>Latour, B. (1993). Nous n’avons jamais été modernes : Essai d’anthropologie symétrique (C. Porter, Trans.). We have never been modern. Cambridge, Mass: Harvard University Press. (Original work published 1991)</p>
<p>Mazlish, B. (1995). The fourth discontinuity: The co-evolution of humans and machines. New Haven, CT: Yale University Press.</p>
<p>Scheffler, S. (2001). Boundaries and allegiances: Problems of justice and responsibility in liberal thought. Oxford, England: Oxford University Press.</p>
<p>Singer, P. (1975). Animal liberation: A new ethics for our treatment of animals. New York, NY: New York Review.</p>
<p>Vincent, J. (2019, April 3). The problem with AI ethics. The Verge. Retrieved from https://www.theverge.com/2019/4/3/18293410 /ai-artificial-intelligence-ethics-boards-charters-problem-bigtech</p>


</section>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>이 글은 필자의 연구논문 “인공지능 시대의 새로운 윤리학: 플로리디 정보윤리학을 중심으로”의 일부를 재구성하여 작성한 글임을 밝힙니다.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>eudemonia38@naver.com<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>플로리디는 기술을 1차 기술, 2차 기술 그리고 3차 기술의 개념들로 구분하고, 기술과 관련한 주/객체의 틀을 사용자(성), 촉진자(성), 그리고 사이(성)으로 유형화한다. 여기서 사이성이 바로 3차 기술에 관계된 것으로, 이 기술은 기술과 기술 사이를 매개하는 기능을 담당한다. 이러한 3차 기술이 출현한 결과 인간과 기술과의 관계라는 기존의 정식 이외에 기술과 기술의 관계에 관한 정식이 새롭게 논의될 필요가 도출된다. 나아가 인간은 이제 기술의 사용자가 아니라 거꾸로 기술의 소비자, 즉 기술이라는 주체(혹은 라뚜르 식으로 말하면 행위소)에 의해 작용되는 대상이 되기도 한다. 플로리디의 기술 구분론은 바로 이런 관계의 새로운 존재론적 양상들을 보여준다는 점에서, 현대 디지털 존재론에서 차별적인 이론적 지위를 차지한다고 볼 수 있다.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>인간의 자율성과 기계의 자율성의 차이에 대한 철학적 고찰로는 포모사(Formosa, 2021)의 논의를 참조.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>최근들어 인공지능 기술과 관련한 철학적 논의들 중에서 ’디지털 존재론’이니 ’정보적 존재론’이니 하는 테마들이 각광받는 이유도 이 틀에서 벗어나지 않는다.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>플로리디는 이 인간상을 그리스 로마 신화 속 데미우르고스 (demiurge), 즉 만드는 자라는 비유를 통해 부연한다. 데미우르고스는 물질 세계를 창조하는 역할을 맡은 신으로 과거 희랍 신화에서는 신중에서도 최고의 신으로 간주되었다. 기독교의 창조론에서와 같이 창조주가 존재하고 있는 질료들(물질들)을 가지고 자연과 인간을 만들었지만 그 정신만은 데미우르고스에 의해 만들어졌다는 신화다.<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "복사완료!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "복사완료!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./basic.html" class="pagination-link" aria-label="인공지능 윤리의 모색을 위한 철학적, 기술학적 기초">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">인공지능 윤리의 모색을 위한 철학적, 기술학적 기초</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./post.html" class="pagination-link" aria-label="포스트휴머니즘과 윤리적 인공지능">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">포스트휴머니즘과 윤리적 인공지능</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>