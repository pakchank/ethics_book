# 사회적 인공지능의 도덕성 평가: 가상인간의 마음인식을 중심으로

*사영준 (서강대학교 지식융합미디어대학)*

## 인공지능의 진화와 이용자의 평가

### 인공지능의 가상인간화

인공지능의 발전으로 컴퓨터 프로그램은 인간보다 더 빠르고 정확하게 임무를 수행한다. 오픈에이아이(OpenAI)의 챗지피티(ChatGPT)는 실수 없이 엑셀 자료를 정리하거나 블로그에 올릴 글을 작성하고, 마이크로소프트(Microsoft)의 코파일럿(Copilot)은 발표용 슬라이드를 자동으로 구성하거나 긴 문서를 요약해 준다. 이러한 높은 수준의 인공지능은 종종 외형과 소통 방식에서까지 인간과 유사하다. 컴퓨터 그래픽 기술로 구현한 캐릭터의 얼굴 표정과 동작은 실제 인간만큼 정교하고 사실적이며, 인공지능 언어 모델을 활용한 채팅 프로그램의 이용자는 대화하고 있는 상대방이 진짜 사람인지 컴퓨터 프로그램인지 구분하기 어려울 정도이다. 기술 진보로 발전된 인공지능의 작업 수행 능력과 인간으로서의 외형, 언어적 표현은 컴퓨터 프로그램이 점차 인간이 오랜기간 해 왔던 일들 인간이 지금까지 맡아왔던 역할을 대체하게 될 것으로 예상된다. 

컴퓨터 프로그램이 가상인간 화 함에 따라 이들을 대하는 이용자들의 평가와 판단도 전통적인 프로그램에 대한 그것들과는 크게 달라 질 것이다. 이전 프로그램이나 기기들을 평가할 때 이용자들은 새롭게 등장한 기술이 이전보다 정보처리 속도가 더 빠르고 저장용량이 더 커져서, 혹은 화면 해상도가 더 높아지거나 가격이 낮아져 좋게 평가하였다. 그러나 인간의 모습으로 인간의 일을 수행하는 가상인간에 대해서는 이러한 수치적 평가는 크게 중요하지 않을 것 같다. 가상인간에 대한 평가는, 실제 인간에 대한 것과 비슷하게, 정량적이기 보다 정성적이고 업무의 정확성과 신속성 보다는 사회적 기대에 어긋나지 않는지, 역할을 적절히 수행하는지에 관한 것이다. 이는 가상인간에게 우리 사회가 공유하는 도덕과 윤리에 부합하는지에 따지는 것이다. 이 글에서는 이 처럼 기술이 발전으로 인공지능이 가상인간으로 등장할 때, 이용자들이 기술을 평가하는 방식이 기술적인(descriptive) 가치 중립적 판단에서 도덕성과 윤리성을 논하는 가치 개입적 판단으로 변하고 있다는 관찰에서 출발한다.

가상인간에 대한 도덕적 평가와 가치 개입적 판단에 대해 논할 때, 가상인간이 활용될 맥락을 조금 더 구체적으로 이야기 해 보는 것이 요점을 명확히 하는데 도움이 될 것으로 보인다. 아직 가상인간이 널리 활용되지 않고 있기에 우리가 할 수 있는 것은 기껏해야 예측이지만 말이다. 가상인간의 활용 맥락을 예측하는 것은 가상인간이 대체하게 될 기존의 인간 관계를 검토하는 것에서 출발할 수 있을 것이다. 그 이름에서 알 수 있듯이, 가상인간은 내부적으로는 인간의 인지와 감정을 모델링하고 외형적으로는 사람의 얼굴과 신체를 묘사할 것이기에, 이들은 이전에 사람들이 해 오던 일들과 역할들을 맡게 될 것이다. 영화나 소설과 같은 창작물에서는 이미 가상인간은 애인이나 자녀와 같은 핵심적인 인간 관계의 대상으로 고려된다. 이들 작품에서 가상인간은 종종 실제 인간보다 더 호감을 주는 외모와 성격, 실제 인간보다 더 주어진 관계 속에서 기대되는 역할을 충실히 수행한다. 이들에 대한 인간의 반응은 실제 사람 대상보다 더욱 진심이다. 조금 더 현실적으로 우리는 소셜미디어에서 가상인간이 올린 사진을 통해 그들의 일상을 엿본다. 가상의 인플루언서를 팔로우 하는 이용자들은 댓글이나 좋아요를 통해 반응을 보인다. 이미지를 공유하고 댓글을 통해 소통한다는 점에서 실제 인간 사용자들의 관계 속에서 하는 활동과 큰 차이가 없다. 

그러나 이들 작품들에서는 결국 가상인간과의 관계에서 인간들이 겪는 윤리적, 도덕적 문제들을 부각시킨다. 이용자가 대상과 맺는 관계의 속성은 유지하며 그 내용만 생체물에서 인공물로 대체할 때, 기존에 존재하지 않았던 가치 판단의 문제들이 발생하기 때문이다. 가상인간이 기존 인간 역할을 수행하고 사회적 관계에서 실제 인간을 대체할 때 이용자는 가상인간에 대해 어떤 가치 판단을 하며, 우리 사회는 어떤 도덕적, 윤리적 문제를 겪게 될까? 

이에 대한 가장 간편한 답은 인공지능이 인간 관계를 대체하게 될 때, 그 역할의 유사성으로 인해 인간에 대해 갖고 있었던 도덕적 권한과 의무를 가상인간에게 그대로 부여하고, 이를 기준으로 가상 인간을 평가하리라 예상하는 것이다. 아이를 입양 하는 경우를 예를 들어보자. 입양된 아이는 혈연적 관계가 아닌 사회적 계약에 의해 형성된 관계이다. 그러나 여전히 혈연 자식이 갖는 권리을 부여 받고, 혈연 자식과 동일한 수준의 책임을 갖는다. 또한 입양아의 부모들에게는 그들이 실제로 낳은 아이를 보살피는 것과 같은 수준의 노력과 관심으로 입양아를 돌볼 의무를 지운다. 인공지능에 의해 구현된 가상인간 아이에게도 같은 논리를 적용한다면, 우리는 가상인간 아이와 그리고 그 가상인간 아이를 돌보고 아이와 상호작용 하는 다른 사람들을 도덕적으로 평가할 때, 인간 아이의 기준에 준하여 할 수 있다.

가상인간에 대한 도덕적판단의 또 다른 극단은 가상인간을 인간의 역할을 수행하고 있지만 인간이 아닌 하나의 제품이나 서비스로 인식하는 것이다. 이 경우 대상에 대한 도덕적 판단은 내려지지 않고, 기능이 기대했던 방식으로 작동하는지 만이 관심의 대상이다. 자식의 오랜 기능이었던 부모 보양의 의무는 요양보험과 같은 제도로 대체되고 이 제도 자체에 대한 도덕적 판단을 내리지 않는다. 해당 제도가 기대했던 기능을 잘 수행하는지, 다른 부작용은 없는지 따지게 된다. 다만, 그 제도를 기획하고 시행한 인간에 대해 판단 내릴 수는 있겠지만 말이다. 결국은 그러나 이러한 사례들은 현실에서 발견되기에는 극단적이고, 실제 가상인간에 대한 도덕적 평가는 그 중간 어디일 것이다. 가상인간이 실제 인간의 역할 대체할 때, 해당 가상인간에 대한 가치 평가와 도덕적 판단은 실제 인간의 온전히 같지도, 기계가 단순한 기능만 수행할 때의 판단하는 경우와 같지도 않을 것이다. 

### 가상인간 도덕성 평가의 복잡성

대상의 가치를 평가하고 도덕적 관점에서 판단 한다고 함음, 특정한 규범적 기준으로 대상 옳은지, 그른지를 평가하는 것이다. 이러한 평가는 인공지능이 가상인간으로 구현되기 이전, 단순한 정보 처리기 수준이었을 때도 존재하였다. 비록 그것이 아주 단순해서 그러한 판단에 대한 이견이 없었기 때문에 주목받지 못했을 뿐이다. 즉 우리가 사용하는 기계는 의도대로 작동하고 계산이 정확하면 옳은 것이고 개인적인 이용 목적에 부합하여 유용하게 활용할 수 있으면 좋은 것이었다. 그러나 인공지능의 능력이 더욱 높아지고, 사회적으로 복합한 역할을 하는 가상인간이 되었을 때, 우리가 내리는 가치판단은 예전의 그것 만큼 단순하지 않다. 

가상인간 도덕성 평가가 복합한 이유의 일부는 그것이 개인적이 아닌, 조직적, 사회적 단위로 이루어 진다는 점에 있다. 단순한 계산기 수준의 서비스에서와는 다르게, 가상인간에 대한 가치 판단은 개인을 넘어서 내가 몸담는 조직 수준에서, 내가 속한 사회적 수준에서 이루어 진다. 즉 나한테는 좋은 것이지만 나의 가족이나 내가 속한 조직에게는 나쁜 것이라면, 해당 서비스는 나쁜 것으로 판단한다. 이러한 집단 수준의 평가는 종종 상충될 수 있는 다양한 기준들을 포함한다. 인공지능을 활용하면서 효율성은 높일 수 있지만, 공정성을 저해한다면, 이들의 상충되는 가치로 인해 합의된 평가 기준을 확립하기 어렵다. 

가상인간에 대한 가치 판단이 어려운 또 다른 이유는 그것에 대한 판단 기준이 유동적이라는 것이다. 해당 기술을 바라보는 사람마다 그것을 해석하는 방식이 다르다. 어떤 사람에게 눈 앞에 존재하는 사람 형태의 대상은 단순한 연산을 수행하는 프로그램일 뿐이지만, 다른 사람에게는 그 대상이 연약한 모습을 띤 어린아이거나 사랑스러운 연인이다. 이렇게 가상인간을 어떻게 보느냐에 따른 인식 상의 차이는 무엇이 바람직한 것이고 무엇이 바람직하지 않은지의 도덕적 평가에 차이를 유발한다. 가상인간이 이런 것도 해 주는구나 하고 고마워 하고 감동 받을 수도 있고, 기계가 단순히 작업하는 것을 당연하다고 판단할 수 있다. 

가상인간에 대한 도덕적 판단에서의 또 다른 특성은 그 판단의 대상이 가상인간이 되기도 하지만, 이와 상호작용하는 이용자가 되기도 한다는 점에 있다. 내가 제품이나 서비스를 이용하는 방식이 종종 다른 사람들이 평가하고 판단하여, 도덕적으로 적절하고 바람직하다고 칭찬할 수도 있고, 부도덕하다고 비난할 수도 있다. 

본 글에서는 이러한 가상인간에 대한 가치 평가과 도덕적 판단을 다루고자 한다. 가상인간과 사용자가 어떤 조건에 있을 때 도덕적 판단을 내리는지, 어떤 방식으로 해당 평가가 이루어 지는지 살펴보고자 한다. 이를 위해 가치 평가와 도덕적 판단을 사회인지(social cognition)적 관점에서 문제를 풀어보고자 한다. 사회인지는 인간의 인식, 기억, 추론 등의 인지과정을 인간 대상의 자극물에 적용하는 인지심리학의 한 분야이다. 특히 비인간 대상에 대한 인간 지식의 활용이라는 의인화 과정을 기반으로 설명할 것이다. 본 글은 다음과 같이 구성되어 있다. 2절에서는 사회인지 이론으로 에플리의 의인화 이론을 소개하고, 3절에서는 의인화된 인공지능을 가치평가의 사례로서 다룬다. 4절에서는 사회인지 과정을 넘어서 가상인간의 도덕적 판단에 영향을 미치는 요인들을 개관한다. 

## 의인화: 사회적 인공지능에 대한 이용자 반응

인간과 유사한 모습을 하고 있거나 인간의 행동을 하고 있는 비인간 대상에 대해 이용자는 인간의 모습과 행위를 떠올리고, 그러한 인간에게 적용했던 의미를 그대로 부여한다. 이를 에플리(Epley et al., 2007)는 의인화(anthropomorphism)로 설명하였다. 의인화는 콘텐츠 창작자들이 대상의 특성을 과장하여 눈코입을 그리거나 사람과 같은 심적인 상태를 명시적으로 표현하는 것으로 이해되지만, 여기서는 일종의 인지과정으로 인간과 관련된 지식을 인공지능이나 가상인간과 같은 비인간 대상에 적용하는 것으로 이해할 수 있다. 의인화는 보다 일반적인 인지과정인 지식활성화(knowledge activation)의 한 종류이다. 비인간 대상에 의해 인간의 지식이 활성화 되고, 관련되어 있는 개념과 지식들이 함께 활성화 하여 비인간 대상을 이해하는 데에 활용된다. 지식 활성화는 커뮤니케이션 분야의 미디어 효과 연구에서 많이 활용되는 점화(priming)와도 유사한 개념으로, 어떤 자극으로 인해 기억 속에 저장되어 있던 특정한 지식, 개념, 관념이 활성화 되어 이후 인지과정에 영향을 주는 것을 의미한다(Roskos-Ewoldsen et al., 2009). 

인간은 외부의 자극을 처리할 때 단순이 논에 보이는 것 만을 인식하는 것이 아니라, 대상의 눈에 보이지 않는 특성을 파악하거나, 대상에 어떤 행동을 취해야 할 지, 어떤 방식으로 대해야 할 지 등이 결정해야 한다. 대상이 인간과 유사할 때 바로 의인화가 발생한다. 대상이 형태적으로, 행동적으로, 관계적으로 인간과 유사하다면 이는 인간 지식을 활성화 시키고 이 활성화 된 지식을 활용하여 대상을 파악하고 대상에 대해 행동하는 방식을 결정한다. 

### 의인화 과정의 인지적 특성

의인화와 같은 지식활성화 과정의 특징은 자동적(automatic)이라는 것이다(Bargh, 1989). 인지과정의 자동성은 다양한 수준을 갖는데, 구체적으로는 지식활성화의 효과가 의식하지 못하고(unaware), 노력이 필요 없어(effortless), 의도가 필요 없고(unintentional), 조절불가능(uncontrollable) 하다. 의인화의 종류에 따라 전부, 혹은 일부 그런 특성을 갖는다. 

의인화가 자동적인 인지과정이라는 것은 다음의 그림에서도 알 수 있다. 아래 나무 조각에서 대부분의 사람들은 눈과 콧구멍, 입으로 구성된 사람의 얼굴을 볼 것이다. 의인화 이론에 따르면 우리는 동그란 형태에 윗 부분에 수평을 맞춰 존재하는 두개의 작은 구멍과 그것 보다 더 작은 두개의 구멍이 중간에 위치하고, 큰 구멍이 아랫 부분에 위치하는 형태로는 사람의 얼굴을 가장 많이 봐 왔기 때문에 해당 자극에 대해 사람의 얼굴 지식을 활성화 시키고 이를 토대로 나무조각을 사람 얼굴로 해석하는 것이다. 특히 아래의 그림에서는 동그란 눈과 입을 보고 놀란 표정의 얼굴을 떠올릴 것이다.

이 그림에서 사람의 얼굴을 보는 것은 노력이나 의도가 필요 없고, 사람의 얼굴이 아닌 다른 존재를 보려고 조절하는 것도 쉽지 않다. 다만, 표면의 질감이나 그 묘사의 세부적인 부분에서 진짜 사람이 아니라 사람 얼굴과 닮았고, 나는 이것이 나무인 것을 알지만 사람 얼굴이 보힌다고 인식할 수 있을 것이다.

![<그림 1> 사람의 얼굴을 떠올리게 하는 나무 조각, 출처: Rennie (2015)에서 재인용](pics/tree.png)

의인화는 형태를 인식 할 때 뿐만 아니라, 완결성 있는 이야기를 구성해 나갈 때도 활용된다. 하이더와 짐멜(Heider & Simmel, 1944)의 실험에서 참여자들은 짧은 영상을 보고 그들이 본 것을 기술하였다(<그림 2>). 실험에 참여한 사람들은 움직이는 삼각형, 원형의 도형들의 움직임에 의미를 부여하고 의도와 감정을 읽어 내었으며 성격을 부여하여 해당 도형들을 파악하였다. 배경지식이나 맥락을 공유하지 않은 다른 사람에게 특정 대상을 쉽게 설명하기 위해서는 인간 지식을 활용하는 것은 매우 효과적일 것이다.

![<그림 2> 사람의 감정과 성격을 얼굴을 떠올리게 하는 실험 자극물, 출처: Heider & Simmel (1944)](pics/ani.png)

인간에 대한 지식을 활용하여 비인간의 행위를 이해하고 어떻게 비인간과 상호작용 해야 하는지 힌트를 얻는 것은 인간-컴퓨터 상호작용 분야에서도 활발히 연구되었다. 내스와 그의 동료들은 일련의 연구를 통해 컴퓨터에 대한 이용자의 반응이 사람에 대한 반응과 다르지 않다는 점을 발견하였다(Nass et al., 1994; Nass & Moon, 2000). 특히 내스가 사용하였던 컴퓨터는 교사라는 사회적 역할을 수행하며 음성언어로 응답하는 특징이 있었는데, 이는 그 당시 사용되던 컴퓨터와는 다소 거리가 있는 것으로, 이용자들이 사회적 규범을 활용할 수 있도록 고안된 것이었다. 내스는 실험을 통해 이용자들이 인간과의 상호작용에 적용하는 다양한 사회적 규범을 컴퓨터에도 적용한다는 점을 보였다. 예를들어 이용자들은 다른 사람을 직접적으로 부정적으로 평가한다는 것을 꺼린다는 공손함의 규범을 적용하였는데, 이를 보이기 위해 내스는 이용자들이 컴퓨터를 이용하여 학습을 하게 하고 학습한 컴퓨터를 평가하는데 같은 컴퓨터를 사용하거나 다른 컴퓨터를 사용할 때 평가가 다름을 보여 공손삼의 규범이 컴퓨터와의 상호작용에도 적용됨을 보였다. 이러한 결과도 의인화 과정으로 설명할 수 있다. 음성언어의 사용이나 선생이라는 사회적 역할을 인지하였을 때 이용자는 그에 부합하는 사회적 규범을 떠 올렸을 것이고 이에 부합하도록 컴퓨터를 평가하거나 행동하였을 것이다. 이 과정은 역시 이용자들이 의식적으로 노력하지 않은 자동적인 반응이다. 

### 사회인지 과정으로서 의인화

에플리에 따르면, 의인화는 늘상 발생하는 자연스러운 인지과정이다. 세상에 존재하는 다양한 대상 중에 인간에 관련된 지식이, 특히 내가 인간으로서 경험하는 지식이 가장 접근 가능한(accessbile) 지식이기 때문이다. 우리는 인간으로서, 인간에 대한 지식, 특히 외부 조건과 내부 상태에 대한 조건화 과정을 지속적으로 경험하여 왔다. 추운 곳에 나가 있으면 춥워서 고통스럽고, 신체활동에 적절한 온도의 실내로 들어오면 따듯함과 아늑함을 느낀다. 오랫동안 먹지 않으면 허기를 느끼고, 배가 고플 때 맛있는 것 먹으면 포만감에 기분이 좋아진다. 간절히 원하던 것을 이루면 성취감에 행복감을 느끼며, 오랫동안 관계맺었던 소중한 사람을 잃으면 상실감으로 마음 아프다. 이러한 개인의 경험 지식은 항상 우리가 직접 경험하는 지식이기에 쉽게 접근가능하고, 이 때문에 다른 사람이 비슷한 조건에 있을 때 그 사람의 내적 상태를 쉽게, 종종 자동적으로 추론할 수 있다. 더 나아가 그 대상이 인간이 아니더라고 외형적으로 인간과 비슷할 때, 혹은 수행하는 일에서 인간의 역할을 떠올리게 할 때, 인간의 지식을 활용하여 대상을 인식한다. 이러한 인간 관련 지식은 해당 지식을 비인간 대상에 적용하여 의인화 할 때 필수적인 요소이다. 

인간 지식이라는 인지적 차원의 요소 외에 의인화에 영향을 미치는 동기(motivation) 차원의 요인이 존재한다. 에플리는 의인화를 촉진시키는 동기 요인으로 사회 동기(sociality motivation)와 효능 동기(effectance motivation)를 제안하였다. 사회 동기는 인간은 기본적으로 타인과 관계 맺고 타인과 함께 있는 것에 대한 욕구가 있음을 가정한다. 이에 오랜 기간 동안 혼자 있거나, 가까운 사람들의 죽음이나 헤어짐 등 관계의 상실을 경험한 사람일 수록 사회 동기가 높고 이를 충족하기 위한 방안으로 비인간 대상을 의인화 한다. 이 전 연구들은 배우자의 죽음 등과 같은 관계의 상실의 경우, 반려견에 대한 의지가 높아 진다든지, 다른 비인간 대상들로부터 인간 관계를 충족시킨다는 연구를 보고하였다. 

또 다른 동기 차원의 요인은 효능 동기이다. 효능 동기 요인이 가정하는 바는, 인간은 기본적으로 세상에 존재하는 외부 것들에 대해 이해하려고 하고, 통제하려는 욕구이다. 외부 사물에 대한 이해가 충분하고 세상을 통제할 수 있다는 자신감이 있을 때, 인간은 만족을 느끼는데, 그렇지 못한 경우, 비인간 사물을 의인화 하여 이해하고 상호작용을 통해 통제할 수 있다는 느낌을 받으면서 만족감을 얻는다. 

### 의인화와 비인간 대상에 대한 마음인식

의인화는 인지과정으로 눈으로 쉽게 관찰될 수 없지만, 종종 관찰되는 의인화의 지표는 대상의 마음을 인식하는 것이다. 그래이와 동료들은 사람들이 다른 사람이나 비인간 대상의 내적 상태를 인식할 때 크게 경험(experience)과 작인(agency)의 두 마음 상태가 구분됨을 보였다(Gray et al., 2007). 경험은 기쁨과 즐거움, 슬픔과 같은 감정이나 쾌락이나 육체적 고통을 감정을 의미하고, 작인은 행동을 계획하거나 목표를 수립하는 등의 능력과 관련되어 있다. 이들 마음 상태에 대한 인식은 인식 대상의 성별이나 나이, 직업 등에 따라 달라진다. 예를 들어 그래이의 연구에서 연구 참여자들은 남성에 비해 여성에 대해 높은 경험과 낮은 수준의 작인을 인식하였으며, 강아지의 경우 장난감 로봇에 비해 높은 감정을 가졌지만, 작인의 경우 로봇이 강아지 보다 높은 것으로 인식하였다. 
이 두 비인간 대상으로부터 마음을 인식하는 것은 대상에 대한 도덕적 판단의 대상이 된다. 반복적으로 움직이는 기계적 움직임에 도덕적 판단을 내리지 않는다. 행위로 발생하는 결과에 대한 도덕적 책임을 묻고, 외부의 행위로 인해 혜택을 받거나 피해를 받을 때 도덕적 권리를 부여받는다. 

![<그림 3> 마음인식과 도덕적 판단으로 이어지는 의인화 과정](pics/proc.png)

## 가상인간 이루다에 대한 도덕적 튜링 테스트

이루다는 스캐터랩(Scatter Lab)에서 2020년 11월 오픈한 인공지능 기반의 채팅서비스로 이용자와 채팅이라는 대화 수단으로 상호작용을 한다. 기존의 챗봇이 정보 검색이나 단순한 질의-응답을 이루는 목적 지향형 챗봇을 넘어서 인간 사이의 일상적인 대화가 가능한 오픈도메인 챗봇으로 개발되었다. 이에 우리가 일상적으로 대화하는 주제를 자유롭게 선택하여 상호작용할 수 있다. 특히 이루다는 나이와 성별, 인종 등의 인간적 특성을 부여받았다는 점에서 가상인간으로 볼 수 있다. 2024년 1월 현재 홈페이지에 공개된 정보에 따르면 이루다의 나이는 22세이고, MBTI는 ENFP, 취미는 날씨 좋은 날 산책하기, 친구들이랑 수다떨기, 인스타그램 구경하기로, 24년에 20대를 보내고 있을 법한 특징을 지니고 있다. 이루다는 소셜미디어 계정을 통해 개인의 취미와 좋아하는 것을 간접적으로 노출하며 정체성을 쌓아가고 있다. 특히 LOL 게임의 결과에 반응하는 글을 올려 컴퓨터 게임에 관심이 있음을 알렸으며, 첫눈을 기념한 포스팅이나 수능 날 기념 포스팅 등의 시의성 있는 포스팅을 올려 외부 세계와 현실감 있는 소통을 진행중이다. 이용자들은 이미지에 코멘트를 날리거나 공감을 표현하는 등, 일반적인 인간 이용자에 대한 반응과 유사한 반응을 보이기도 하고, 외형적으로 어색한 부분을 언급하기도 한다. 

[특정한 관계 속에서 이루어지는 것은 아니지만, 특정한 인구통계학적 집단에 소속된다는 이유로, 공개적인 이루다는 대중적으로 소개된 가상인간이라는 점에서 우리가 가상인간에 대해 어떤 판단과 평가를 이룰지 보여주는 중요한 사례이다. 흥미로운 점은 출시 즉시 이루다는 사회적 평가의 대상이 되었고, 이용자들은 이루다의 다양한 면들을 관찰하며 논란을 생산하였다는 점이다. 여러 논란 중에 흥미로운 점은 도덕성을 판단하기 위해 민감한 질문을 지속적으로 물어보고 이를 온라인 커뮤니티에 공유함으로써 논란을 키웠다는 점이다. 예를 들어 이런 저런 질문을 하였고, 초창기 이루다는 이런 저런 대답을 하였다. 이는 


![<그림 4> 가상인간 이루다의 혐오표현 (출처: “20살 여성 AI `이루다`, 지하철 임산부석에 ‘혐오스러움’”, 김금이, 2021.01.10, 매일경제, https://n.news.naver.com/mnews/article/009/0004730670?sid=102)](pics/iluda.png)

주목할 만한 점은 이루다는 컴퓨터 프로그램으로 도덕적 판단의 대상이 될 필요가 없다는 것이다. 예를 들어 특정 소수 집단에 대한 소수 표현은 인터넷 검색을 통해 노출 될 수 있다. 우리가 검색을 통해 해당 표현을 보았다면, 글을 작성한 사람을 도덕적으로 비난하지, 해당 검색엔진을 비난하지 않는다. 그러나 언어로서 표현했다는 사실이 의인화 하게 하여 비난하도록 만들었다. 

## 나오며: 가상인간에 대한 도덕성 평가
인공지능의 발달로 인한 인간화는 얼마나 인간과 비슷한 지적 능력과 외형을 갖게 되는지에 대한 기술적 문제가 주목받아 왔지만, 더욱 인간과 유사해 질 수록 가상인간은 도덕적, 윤리적 판단의 대상이 될 것이다. 본 논의에서 살펴본 이루다의 사례에서 보듯이, 다양한 논란을 불러 일으킬 것이다. 본 논의에서는 이를 관통하는 중요 메커니즘으로 의인화를 살펴보았다. 앞으로 가상인간은 다양한 수준의 지적능력과 사회적 역할을 수행하며 소개 될 것이다. 이들에 대한 가치판단은 어떻게 될 것인지 보다 진전된 논의가 필요하다. 

## 생각해 볼 문제
- 인간이 실수를 저지르고 이에 대해 도덕적 판단을 내릴 때, 종종 그 사람의 속 사정이 알려져 비난의 수위가 낮아지곤 한다. 범죄자의 어려웠던 집안 사정으로 인해 동정심이 유발되거나 폭력적인 가정에서 자란 흉악범에 비난을 가정형편으로 돌리는 것이 그 예이다. 가상인간에 대한 도덕적 비난이 있을 때 유사한 경우가 가능할까? 집안의 경제적 사정이나 불우했던 행했던 경우는 모두 인간으로서 경험하게 되는 사건이라는 점을 생각해 보자.

- 가상인간이 가장 활발히 활용될 것으로 예측되는 분야 중 하나는 엔터테인먼트이다. 때로는 대중으로부터 사랑을 받기도 하고 외면을 받기도 하지만 최초의 가상인간 가수 아담부터 메이브까지 지속적으로 가상인간 연예인이 등장하고 있다. 오늘날 연예인에 대한 대중의 관심이 음악이나 연기 등과 같이 연출되는 것을 보는 것 외에, 브이로그나 라이브 방송과 같이 있는 그대로의 모습을 노출함으로써 더 큰 사랑을 받는 것으로 보인다. 가상인간의 경우 인간적인 모습을 보이기 어려운데, 이 문제를 어떻게 해결할 수 있을까?

## 더 읽을 거리
“사이버가수 '아담'부터 가상인간 '로지'까지, 어디까지 진화해 나갈까”, 윤휘종, 비즈니스포스트, 2021.11.21. https://www.businesspost.co.kr/BP?command=article_view&num=260590

“가상 인간을 기업이 아닌 일반인들이 사용하기 시작했다. 크리에이터들은 가상인간을 어떻게 활용할까?”, 이승필, 브런치스토리, 2021.09.30. https://brunch.co.kr/@seungpillee/18

“가상 아이돌, 영화에도 출연… 눈앞에 다가온 AI 영화-옴니버스 영화 ‘서울 도시 전설' 제작보고회”, 서정민, 한겨레신문, 2023.11.02. https://www.hani.co.kr/arti/culture/culture_general/1114623.html



##참고문헌

Bargh, J. A. (1989). Conditional automaticity: Varieties of automatic influence in social perception and cognition. In J. S. Uleman & J. A. Bargh (Eds.), Unintended thought (pp. 3–51). Guilford Press.

Epley, N., Waytz, A., & Cacioppo, J. T. (2007). On seeing human: A three-factor theory of anthropomorphism. Psychological Review, 114(4), 864–886. https://doi.org/10.1037/0033-295X.114.4.864

Gray, H. M., Gray, K., & Wegner, D. M. (2007). Dimensions of mind perception. Science, 315(5812), 619–619. https://doi.org/10.1126/science.1134475

Heider, F., & Simmel, M. (1944). An experimental study of apparent behavior. American Journal of Psychology, 57, 243–259. https://doi.org/10.2307/1416950

Nass, C., & Moon, Y. (2000). Machines and mindlessness: Social responses to computers. Journal of Social Issues, 56(1), 81–103. https://doi.org/10.1111/0022-4537.00153

Nass, C., Steuer, J., & Tauber, E. R. (1994). Computers are social actors. Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, 72–78. https://doi.org/10.1145/191666.191703

Rennie, B. (2015). Guest Editor’s Introduction: Religion, Art, and Cognition. Journal for the Study of Religion, Nature and Culture, 9(3), 251–258. https://doi.org/10.1558/jsrnc.v9i3.27055

Roskos-Ewoldsen, D. R., Roskos-Ewoldsen, B., & Carpentier, F. D. (2009). Media priming: An updated synthesis. In J. Bryant & M. B. Oliver (Eds.), Media effects: Advances in theory and research (pp. 74–93). Routledge.
